\documentclass{InsightArticle}
\usepackage{multirow}
\usepackage[table,xcdraw]{xcolor}
\usepackage[dvips]{graphicx}
%  hyperref should be the last package to be loaded.
\usepackage[bookmarks,
bookmarksopen,
backref,
colorlinks,linkcolor={blue},citecolor={blue},urlcolor={blue},
]{hyperref}

\title{$n$D morphological contour interpolation}

%
% NOTE: This is the last number of the "handle" URL that
% The Insight Journal assigns to your paper as part of the
% submission process. Please replace the number "1338" with
% the actual handle number that you get assigned.
%
\newcommand{\IJhandlerIDnumber}{1338}

% Increment the release number whenever significant changes are made.
% The author and/or editor can define 'significant' however they like.
\release{0.01}

\author{D{\v z}enan Zuki{\' c}$^{1}$, Jared Vicory$^{2}$, Matthew McCormick$^{3}$ and Paul Yushkevich$^{4}$}
\authoraddress{$^{1}$dzenan.zukic@kitware.com\\
               $^{2}$jared.vicory@kitware.com\\
							 $^{3}$matt.mccormick@kitware.com\\
               $^{4}$pauly2@mail.med.upenn.edu}

\begin{document}
\IJhandlefooter{\IJhandlerIDnumber}

\ifpdf
\else
   \DeclareGraphicsExtensions{.eps,.jpg,.gif,.tiff,.bmp,.png}
   \DeclareGraphicsRule{.jpg}{eps}{.jpg.bb}{`convert #1 eps:-}
   \DeclareGraphicsRule{.gif}{eps}{.gif.bb}{`convert #1 eps:-}
   \DeclareGraphicsRule{.tiff}{eps}{.tiff.bb}{`convert #1 eps:-}
   \DeclareGraphicsRule{.bmp}{eps}{.bmp.bb}{`convert #1 eps:-}
   \DeclareGraphicsRule{.png}{eps}{.png.bb}{`convert #1 eps:-}
\fi

\maketitle

\ifhtml
\chapter*{Front Matter\label{front}}
\fi


\begin{abstract}
\noindent
This document describes a new class, \code{itk::MorphologicalContourInterpolator},
which implements a method proposed by Albu et al~\cite{Albu2008}.
This class is $n$-dimensional, and supports inputs of 3 or more dimensions.
`Slices' are $n-1$-dimensional, and can be both automatically detected and manually set.

The class is efficient in both memory used and execution time.
It requires little memory in addition to allocation of input and output images.
The implementation is multi-threaded, and processing one of the test inputs
takes around 1-2 seconds on a quad-core processor.

The class is tested to operate on both \doxygen{Image} and \code{itk::RLEImage}.
Since all the processing is done on extracted slices,
usage of \code{itk::RLEImage} for input and/or affects performance to a limited degree.

This class is implemented to ease manual segmentation in ITK-SNAP \url{www.itksnap.org}.
The class, along with test data and automated regression tests is packaged as an ITK
remote module \url{https://github.com/KitwareMedical/ITKMorphologicalContourInterpolation}.
\end{abstract}

\IJhandlenote{\IJhandlerIDnumber}

\tableofcontents


\section{Introduction}

Proliferation of automatic segmentation algorithms is on the rise,
but their performance is measured against a manually created `gold standard' segmentation.
Additionally, manual segmentation is sometimes required for other purposes.

As anyone who has ever done manual image segmentation can tell you,
it becomes monotonous very quickly.
This is especially true for high-resolution 3D images,
i.e. for 3D images with thin `slices' (because there are many of them).
The classic `cure' for this is inter-slice interpolation (Fig.~\ref{fig:InOut}).
Namely, in regions where the anatomy is slowly changing and adjacent slices are quite similar,
some slices can be skipped by a human segmenter and then interpolated by an algorithm.

\begin{figure}[htb]
\center
\includegraphics[scale=0.265]{In1.png}
\includegraphics[scale=0.265]{Out1.png}
\includegraphics[scale=0.265]{In2.png}
\includegraphics[scale=0.265]{Out2.png}
\itkcaption[InOut]{Examples of inputs (left) and outputs (right).
First row: two labels, manual segmentation on coronal slices only.
Second row: four labels, manual segmentation along all three principal axes of the body.}
\label{fig:InOut}
\end{figure}


\section{Class description}

\code{itk::MorphologicalContourInterpolation} is a class derived from
\doxygen{ImageToImageFilter}.
Input is $n$-dimensional, usually 3D.
`Slices' are cross-sections along one axis, usually 2D.
Locations of manually segmented slices can be set using
\code{SetUseCustomSlicePositionsOn} and \code{SetLabeledSliceIndices}.
The default is auto-detection of manually segmented slices using a heuristic.
%If there is a pixel whose all 4-way neighbors belong the the same label
%except along one axis, and along that axis its neighbors are 0 (background),
%then that axis should be interpolated along.

The filter can be restricted to interpolate only along one axis
and/or to interpolate just one label.
The default is to interpolate all labels along all axes.

The shapes in `source slices' need to be aligned for interpolation.
Albu's method calls for alignment with
minimum shape displacement achieving maximum shape overlap.
However that alignment requires inefficient exhaustive search,
so \code{HeuristicAlignment} is implemented and enabled by default.
\code{HeuristicAlignment} uses breadth-first-search strategy
with `no translation' and `centroid alignment' as first two seeds.
`No translation' seed is required to prevent exceptional cases in which
`centroid alignment' produces no overlap for some concave shapes.
The search is terminated when further expansion of search space
(relative translations) leads to pixel overlap counts
less than 90\% of the current maximum.

The most compute intensive part of the algorithm~\cite{Albu2008}
is generation of two dilation sequences which transform the intersection
of the two shapes into each of them.
Those dilations can be done with either \doxygen{BinaryBallStructuringElement}
or \doxygen{BinaryCrossStructuringElement}.
The option \code{UseBallStructuringElement} controls which one is used.

As generation of the dilation sequences is computationally intensive,
we also experimented with usage of distance field.
A histogram of pixel counts of shapes `A' and `B' for different distances
can be used to calculate a threshold which directly produces median shape.
However, this approach loses the geodesic aspect of shape growth and
is not much faster (which was our hope) for our test examples.
We decided to retain it, and it is activated by \code{UseDistanceTransform}.

To minimize the usage of memory, the output of interpolation is written
directly into the output image.
The interpolation is done on each axis successively,
in the order of increasing indices (0, 1, 2, ... or X, Y, Z, ...).
In case of conflicts between labels,
the label with bigger number has precedence (gets written into output).
This is in contrast to `not writing pixels which have already been written once'.
The chosen convention ensures that the output is not dependent on the
variability of execution introduced by multi-threading.
This elimination of variability also improves
reliability of automated regression tests.


\section{Performance measurements}

The remote module%~\url{https://github.com/KitwareMedical/ITKMorphologicalContourInterpolation}
contains 360 automated regression tests, 120 for each `interpolation algorithm'
(repeated dilations with ball element, repeated dilations with cross element, and distance transform).
However the execution time is practically independent of the structuring element (ball/cross),
and only somewhat faster for distance transform approach.
Therefore, the performance was measured only for ball structuring element.

Also, about a third of the tests use handcrafted test images
which were useful during the class development, and are of little relevance now.
Thus, table~\ref{tab:time} and figure~\ref{fig:time} only contain measurements for realistic inputs.
Two of those inputs are depicted in Fig.~\ref{fig:InOut}.

\begin{table}[hbt]
	\centering
		\begin{tabular}{llll}
								 & \textbf{RLEImage} & \textbf{itk::Image} & \textbf{itk::Image+Conversion} \\
		\textbf{PC1} & 1.97              & 1.43                & 1.54                           \\
		\textbf{PC2} & 1.35              & 1.13                & 1.12                          
		\end{tabular}
	\caption{Average time taken to process an input. Unit: seconds.
	First two columns represent the image type over which the filter was templated.
	The third column shows time of running the filter on Image
	and doing double conversion of the input (Image$\rightarrow$RLEImage$\rightarrow$Image).}
	\label{tab:time}
\end{table}

\begin{figure}[htb]
\center
\includegraphics{Time.pdf}
\itkcaption[Time]{Average time taken to process an input. Unit: seconds.
See Tab.~\ref{tab:time} for explanation of measurement points.}
\label{fig:time}
\end{figure}

The tests were done on two computers.
PC1 has Ubuntu 16.04, Core2 Q9300 quad core processor, 4 GB of RAM,
a classic hard disk and was bought in 2008.
PC2 has Windows 7, Xeon E3-1220 quad core processor, 32 GB of RAM,
a solid state drive and was bought in 2015.

These results show that usage of \code{itk::RLEImage} has a performance
penalty over \doxygen{Image}, but that is not significant (20-30\%).

\section{Acknowledgments}

This work is supported by NIH grant R01 EB014346,
`Continued development and maintenance of the ITK-SNAP 3D image segmentation software'.

\bibliographystyle{plain}
\bibliography{InsightJournal}

\end{document}
