\documentclass{InsightArticle}
\usepackage{multirow}
\usepackage[table,xcdraw]{xcolor}
\usepackage[dvips]{graphicx}
%  hyperref should be the last package to be loaded.
\usepackage[bookmarks,
bookmarksopen,
backref,
colorlinks,linkcolor={blue},citecolor={blue},urlcolor={blue},
]{hyperref}

\title{$n$D morphological contour interpolation}

%
% NOTE: This is the last number of the "handle" URL that
% The Insight Journal assigns to your paper as part of the
% submission process. Please replace the number "1338" with
% the actual handle number that you get assigned.
%
\newcommand{\IJhandlerIDnumber}{1338}

% Increment the release number whenever significant changes are made.
% The author and/or editor can define 'significant' however they like.
\release{0.2}

\author{D{\v z}enan Zuki{\' c}$^{1}$, Jared Vicory$^{2}$, Matthew McCormick$^{3}$
Laura E.M. Wisse$^{4}$, Guido Gerig$^{5}$, Paul Yushkevich$^{6}$ and Stephen Aylward$^{7}$}
\authoraddress{$^{1}$Kitware Inc., dzenan.zukic@kitware.com\\
               $^{2}$Kitware Inc., jared.vicory@kitware.com\\
               $^{3}$Kitware Inc., matt.mccormick@kitware.com\\
               $^{4}$Penn Image Computing \& Science Laboratory, Department of Radiology, University of Pennsylvania, laura.wisse@uphs.upenn.edu\\
               $^{5}$NYU Tandon School of Engineering, Department of Computer Science and Engineering, gerig@nyu.edu\\
               $^{6}$Penn Image Computing \& Science Laboratory, Department of Radiology, University of Pennsylvania, pauly2@mail.med.upenn.edu\\
               $^{7}$Kitware Inc., stephen.aylward@kitware.com}


\begin{document}
\IJhandlefooter{\IJhandlerIDnumber}

\ifpdf
\else
   \DeclareGraphicsExtensions{.eps,.jpg,.gif,.tiff,.bmp,.png}
   \DeclareGraphicsRule{.jpg}{eps}{.jpg.bb}{`convert #1 eps:-}
   \DeclareGraphicsRule{.gif}{eps}{.gif.bb}{`convert #1 eps:-}
   \DeclareGraphicsRule{.tiff}{eps}{.tiff.bb}{`convert #1 eps:-}
   \DeclareGraphicsRule{.bmp}{eps}{.bmp.bb}{`convert #1 eps:-}
   \DeclareGraphicsRule{.png}{eps}{.png.bb}{`convert #1 eps:-}
\fi

\maketitle

\ifhtml
\chapter*{Front Matter\label{front}}
\fi


\begin{abstract}
\noindent
This document describes a new class, \code{itk::MorphologicalContourInterpolator},
which implements a method proposed by Albu et al. in 2008.
Interpolation is done by first determining correspondence between shapes on adjacent
segmented slices by detecting overlaps, then aligning the corresponding shapes,
generating transition sequence of one-pixel dilations and taking the median as result.
Recursion is employed if the original segmented slices are separated by more than one empty slice.

This class is $n$-dimensional, and supports inputs of 3 or more dimensions.
`Slices' are $n-1$-dimensional, and can be both automatically detected and manually set.
The class is efficient in both memory used and execution time.
It requires little memory in addition to allocation of input and output images.
The implementation is multi-threaded, and processing one of the test inputs
takes around 1-2 seconds on a quad-core processor.

The class is tested to operate on both \doxygen{Image} and \code{itk::RLEImage}.
Since all the processing is done on extracted slices,
usage of \code{itk::RLEImage} for input and/or output affects performance to a limited degree.

This class is implemented to ease manual segmentation in ITK-SNAP (\url{www.itksnap.org}).
The class, along with test data and automated regression tests is packaged as an ITK
remote module \url{https://github.com/KitwareMedical/ITKMorphologicalContourInterpolation}.
\end{abstract}

\IJhandlenote{\IJhandlerIDnumber}

\newpage

\tableofcontents


\section{Introduction}

Proliferation of automatic segmentation algorithms is on the rise,
but their performance is measured against a manually created `gold standard' segmentation~\cite{py06nimg}.
Additionally, manual segmentation is required to train automatic segmentation algorithms,
as well as in problems where automatic segmentation is not sufficiently reliable.

As anyone who has ever done manual image segmentation can attest,
it becomes monotonous very quickly and thus also may become less reliable.
This is especially true for high-resolution 3D images with many slices.
One strategy to reduce the need for repetitive tracing is inter-slice interpolation (Fig.~\ref{fig:InOut}).
Namely, in regions where the anatomy is slowly changing and adjacent slices are quite similar,
some slices can be skipped by a human segmenter and then interpolated by an algorithm.

\begin{figure}[!htb]
\center
\includegraphics[scale=0.265]{In1.png}
\includegraphics[scale=0.265]{Out1.png}
\includegraphics[scale=0.265]{In2.png}
\includegraphics[scale=0.265]{Out2.png}
\itkcaption[InOut]{Examples of inputs (left) and outputs (right).
First row: hippocampal sub-fields in in-vivo $T_2$-weighted MRI,
two labels, manual segmentation on coronal slices only.
Second row: amygdalar nuclei in ex-vivo 9.4 Tesla MRI,
four labels, manual segmentation along all three principal axes of the body.}
\label{fig:InOut}
\end{figure}

Albu's method~\cite{Albu2008} is centered around interpolating a single shape on
slice $i$ into a single shape on slice $j$.
Shapes are contiguous groups of pixels with the same label value.
Correspondence between shapes is determined by examining overlaps
of shapes from from slices $i$ and $j$.
If a shape on one slice overlaps more than one shape on the other slice,
the one shape is split into disjoint regions based on dilations
starting from overlaps (intersections),
and those disjoint regions are interpolated as if they were separate shapes.

Before interpolating $i$ shape into $j$ shape, they are aligned
to achieve maximum shape overlap with minimum shape displacement.
When writing out the interpolated slices, the opposite translation is applied.
To create gradual transition, the overlap shape $o$ is created
by intersection of shapes $i$ and $j$.
Then two transition sequences are generated: $o\rightarrow i$ and $o\rightarrow j$.
Each step in these sequences is a one-pixel dilation of the previous step,
constrained by the final shape (to not leak outside).
Then $o\rightarrow j$ sequence is reversed (to form $j\rightarrow o$) and
merged with $o\rightarrow i$ by forming union at each step.
The resulting sequence is a smooth transition from shape $i$ into $j$.
The final interpolating shape is the median in the sequence, such that its
pixel-count difference to both $i$ and $j$ shapes is as equal as possible.

This approach retains some distinctive features, unlike some surface interpolation
approaches which tend to smooth the shapes which are being interpolated.
If there is large overlap and no shifting of structures
between contours being interpolated, this method works well.
If the genus of the object changes, this approach might also be better
than some traditional shape interpolation methods.
But if a structure appears to be moving along the boundary
(an elliptical shape structure appears to rotate between slices),
if the center-line of the object is not orthogonal to the slices
so that the object appears to translate between slices, or if the overlap is low,
then a shape-based method (that incorporates constraints to preserve
boundary curvature or the total area of the interpolated structure) might be preferred.
Also, this method does not involve changing representation into a surface,
so it can be implemented efficiently which is of significance in practice.

Manual corrections are possible after invoking this filter through ITK-SNAP,
as well as undo, redo and other standard editing features.
This is important for cases of imperfect interpolation,
and correcting an incorrect segmentation is usually quicker than
doing it manually in each slice.

\section{Class description}

\code{itk::MorphologicalContourInterpolation} is a class derived from
\doxygen{ImageToImageFilter}.
Input is $n$-dimensional, usually 3D.
`Slices' are cross-sections along one axis, usually 2D.
Locations of manually segmented slices can be set using
\code{SetUseCustomSlicePositionsOn} and \code{SetLabeledSliceIndices}.
The default is auto-detection of manually segmented slices using a heuristic.
%If there is a pixel whose all 4-way neighbors belong the the same label
%except along one axis, and along that axis its neighbors are 0 (background),
%then that axis should be interpolated along.

The filter can be restricted to interpolate only along one axis
and/or to interpolate just one label.
The default is to interpolate all labels along all axes.

The shapes in `source slices' need to be aligned for interpolation.
Albu's method~\cite{Albu2008} calls for alignment
which requires inefficient exhaustive search,
so \code{HeuristicAlignment} is implemented and enabled by default.
\code{HeuristicAlignment} uses breadth-first-search strategy
with `no translation' and `centroid alignment' as first two seeds.
`No translation' seed is required to prevent exceptional cases in which
`centroid alignment' produces no overlap for some concave shapes.
The search is terminated when further expansion of search space
(relative translations) leads to pixel overlap counts
less than 90\% of the current maximum.

The most compute intensive part of the algorithm
is the generation of two dilation sequences which gradually transform the shapes.
Those dilations can be done with either \doxygen{BinaryBallStructuringElement}
or \doxygen{BinaryCrossStructuringElement}.
The option \code{UseBallStructuringElement} controls which one is used.

As generation of the dilation sequences is computationally intensive,
we also experimented with usage of distance field.
A histogram of pixel counts of shapes `A' and `B' for different distances
can be used to calculate a threshold which directly produces median shape.
However, this approach loses the geodesic aspect of shape growth and
is not much faster (which was our hope) for our test examples.
We decided to retain it, and it is activated by \code{UseDistanceTransform}.

To minimize the usage of memory, the output of interpolation is written
directly into the output image.
The interpolation is done on each axis successively,
in the order of increasing indices (0, 1, 2, 3 ... or X, Y, Z, t ...
or sagittal, coronal, axial, temporal ...), and a union is implicitly made.
In case of conflicts between labels,
the label with bigger number has precedence (gets written into output).
This is in contrast to `keep results of earlier processed axes and labels'
(not writing pixels which have already been written once)
and `overwrite the result by latest processed axis or label'.
The chosen convention ensures that the output is not dependent on the
variability of execution introduced by multi-threading.
This elimination of variability also improves
reliability of automated regression tests.


\section{Performance measurements}

The remote module %~\url{https://github.com/KitwareMedical/ITKMorphologicalContourInterpolation}
contains 360 automated regression tests, 120 for each `interpolation algorithm'
(repeated dilations with ball element, repeated dilations with cross element, and distance transform).
However the execution time is practically independent of the structuring element (ball/cross),
and only somewhat faster for distance transform approach.
Therefore, the performance was measured only for ball structuring element.

Also, about a third of the tests use handcrafted test images
which were useful during the class development, and are of little relevance now.
Thus, table~\ref{tab:time} and figure~\ref{fig:time} only contain measurements for realistic inputs.
Two of those inputs are depicted in Fig.~\ref{fig:InOut}.

\begin{table}[hbt]
    \centering
        \begin{tabular}{llll}
                     & \textbf{RLEImage} & \textbf{itk::Image} & \textbf{itk::Image+Conversion} \\
        \textbf{PC1} & 1.97              & 1.43                & 1.54                           \\
        \textbf{PC2} & 1.35              & 1.13                & 1.12
        \end{tabular}
    \caption{Average time taken to process an input. Unit: seconds.
    First two columns represent the image type over which the filter was templated.
    The third column shows time of running the filter on Image
    and doing double conversion of the input (Image$\rightarrow$RLEImage$\rightarrow$Image).}
    \label{tab:time}
\end{table}

\begin{figure}[htb]
\center
\includegraphics{Time.pdf}
\itkcaption[Time]{Average time taken to process an input. Unit: seconds.
See Tab.~\ref{tab:time} for explanation of measurement points.}
\label{fig:time}
\end{figure}

The tests were done on two computers.
PC1 has Ubuntu 16.04, Core2 Q9300 quad core processor, 4 GB of RAM,
a classic hard disk and was bought in 2008.
PC2 has Windows 7, Xeon E3-1220 quad core processor, 32 GB of RAM,
a solid state drive and was bought in 2015.

These results show that usage of \code{itk::RLEImage} has a performance
penalty over \doxygen{Image}, but that is not significant (20-30\%).

\section{Acknowledgments}

This work is supported by NIH grant R01 EB014346,
`Continued development and maintenance of the ITK-SNAP 3D image segmentation software'.

\bibliographystyle{plain}
\bibliography{InsightJournal}

\end{document}
